import { useEffect, useRef, useState } from "react";
import * as faceapi from "face-api.js";
import { beepSound } from "../../data/Data"
import { Loader2 } from "lucide-react";

export default function FaceVerify({ isOpen, onClose, onCapture }) {
    const videoRef = useRef(null);
    const canvasRef = useRef(null);
    const streamRef = useRef(null);
    const beep = useRef(new Audio(beepSound));

    const [captured, setCaptured] = useState(false);
    const [hint, setHint] = useState("ƒê∆∞a khu√¥n m·∫∑t v√†o khung");

    /* =======================
      CONFIG KHUNG CHU·∫®N
   ======================= */
    const FRAME = {
        width: 208,   // w-52
        height: 256,  // h-64
        tolerance: 35
    };

    /* =======================
       1. Load face-api model
    ======================= */
    useEffect(() => {
        const loadModels = async () => {
            await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
        };
        loadModels();
    }, []);

    /* =======================
       2. Start / Stop camera
    ======================= */
    useEffect(() => {
        if (!isOpen) return;

        startCamera();

        return () => {
            stopCamera();
        };
    }, [isOpen]);

    /* =======================
      RESET STATE
   ======================= */
    useEffect(() => {
        if (isOpen) {
            setCaptured(false);
            setHint("ƒê∆∞a khu√¥n m·∫∑t v√†o khung");
        }
    }, [isOpen]);

    /* =======================
       4. Auto detect face
    ======================= */
    /* =======================
       AUTO DETECT + G·ª¢I √ù
    ======================= */
    useEffect(() => {
        if (!isOpen) return;

        const detect = async () => {
            const video = videoRef.current;
            if (!video) return;
            if (!faceapi.nets.tinyFaceDetector.isLoaded) return;
            if (video.videoWidth === 0) return;
            if (captured) return;

            const detections = await faceapi.detectAllFaces(
                video,
                new faceapi.TinyFaceDetectorOptions({
                    inputSize: 416,
                    scoreThreshold: 0.6
                })
            );

            if (detections.length === 0) {
                setHint("Kh√¥ng th·∫•y khu√¥n m·∫∑t");
                return;
            }

            if (detections.length > 1) {
                setHint("Ch·ªâ ƒë·ªÉ m·ªôt khu√¥n m·∫∑t trong khung");
                return;
            }

            const box = detections[0].box;
            console.log("FACE BOX:", box.width, box.height);
            const message = analyzeFace(box);
            setHint(message);

            if (message === "Gi·ªØ nguy√™n, ƒëang nh·∫≠n di·ªán‚Ä¶") {

                capture();
            }
        };

        const interval = setInterval(detect, 400);
        return () => clearInterval(interval);
    }, [isOpen, captured]);

    /* =======================
      PH√ÇN T√çCH G·ª¢I √ù
   ======================= */
    const analyzeFace = (box) => {
        const video = videoRef.current;
        if (!video) return "ƒêang kh·ªüi ƒë·ªông camera‚Ä¶";

        const videoW = video.videoWidth;
        const videoH = video.videoHeight;

        // T√ÇM KHUNG OVAL (gi·ªØa video)
        const frameCenterX = videoW / 2;
        const frameCenterY = videoH / 2;

        const faceCenterX = box.x + box.width / 2;
        const faceCenterY = box.y + box.height / 2;

        const dx = faceCenterX - frameCenterX;
        const dy = faceCenterY - frameCenterY;

        // Ki·ªÉm tra kho·∫£ng c√°ch
        if (box.width < FRAME.width * 0.75) {
            return "ƒê∆∞a khu√¥n m·∫∑t l·∫°i g·∫ßn h∆°n";
        }

        if (dx > FRAME.tolerance) return "D·ªãch sang tr√°i m·ªôt ch√∫t";
        if (dx < -FRAME.tolerance) return "D·ªãch sang ph·∫£i m·ªôt ch√∫t";

        if (dy > FRAME.tolerance) return "H·∫° khu√¥n m·∫∑t xu·ªëng";
        if (dy < -FRAME.tolerance) return "N√¢ng khu√¥n m·∫∑t l√™n";

        return "Gi·ªØ nguy√™n, ƒëang nh·∫≠n di·ªán‚Ä¶";
    };

    /* =======================
       CAMERA HANDLER
    ======================= */
    const startCamera = async () => {
        try {

            if (!videoRef.current) {
                requestAnimationFrame(startCamera);
                return;
            }

            stopCamera();

            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    facingMode: "user",
                    width: 540,
                    height: 720
                }
            });

            streamRef.current = stream;

            // ‚úÖ check l·∫°i l·∫ßn n·ªØa
            if (!videoRef.current) return;

            videoRef.current.srcObject = stream;
            await videoRef.current.play();

        } catch (err) {
            console.error("Camera error:", err);
        }
    };

    const stopCamera = () => {
        if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            streamRef.current = null;
        }

        if (videoRef.current) {
            videoRef.current.srcObject = null;
        }
    };

    /* =======================
       AUTO CAPTURE
    ======================= */
    const capture = () => {
        if (captured) return;
        setCaptured(true);

        console.log("üì∏ CAPTURE TRIGGERED");

        const video = videoRef.current;
        const canvas = canvasRef.current;

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, 0, 0);

        canvas.toBlob(blob => {
            const file = new File([blob], "face.jpg", { type: "image/jpeg" });
            onCapture(file);
            if (beep.current) {
                beep.current.currentTime = 0;
                beep.current.play().catch(e => console.log("Kh√¥ng ph√°t ƒë∆∞·ª£c √¢m thanh:", e));
            }

            // delay ƒë·ªÉ th·∫•y hi·ªáu ·ª©ng ch·ª•p
            setTimeout(() => {
                onClose();
            }, 3000);

        }, "image/jpeg", 0.9);
    };

    if (!isOpen) return null;

    return (
        <div className="bg-gray-50 p-5 border border-gray-300 rounded-lg overflow-hidden">

            <div className="relative w-full h-[420px] bg-black rounded-lg overflow-hidden">

                {/* Camera */}
                <video
                    ref={videoRef}
                    autoPlay
                    playsInline
                    className="w-full h-full object-cover"
                />

                {/* Face frame */}
                <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
                    <div className={`w-52 h-64 rounded-full opacity-80 border-8
                        ${!captured ? "border-white-400" : "border-emerald-500"}
                        `} />
                    {captured ?
                        <div className="absolute inset-0 flex items-center justify-center">
                            <Loader2 className="h-12 w-12 animate-spin text-white" />
                        </div> :
                        null}
                </div>



                <canvas ref={canvasRef} className="hidden" />
            </div>
            {/* G·ª¢I √ù REALTIME */}
            <div className="w-full h-12 mt-5 flex bg-yellow-300 border border-2 rounded-lg border-yellow-400 items-center justify-center">
                <span className="text-heading text-lg font-semibold">{hint}</span>
            </div>
        </div>

    );
}